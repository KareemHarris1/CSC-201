---
title: "Lab 5"
author: "D. Howell"
date: "11/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

> Due November 21. No late submissions. 

## Intro
This lab is about comparing the predictive performance (accuracy) of a variety of models that we have surveyed in the course. We'll use the heart disease data set from the Random Forest class (data set details [here](http://htmlpreview.github.io/?https://raw.githubusercontent.com/drehow/CSC-201/master/2020_Fall/20201102_Random_Forest/RF_notes.html))

## Prompt
The script to clean and prepare the data for analysis is pasted below along with the training, prediction, and evaluation of a Random Forest model. At the end of the script, you should add code that performs the same steps as what is done on the random forest model, but for a Naive Bayes and the four different SVM kernel shapes (linear, radial, sigmoid, polynomial). Once you have trained, tested, and produced a confusion matrix for those 5 models, make a visualization comparing the accuracy of each of the models as a percentage (100 * correct predictions / total predictions) on the test set. 

```{r, warning=FALSE, message=FALSE}
library(randomForest) # for RF model
library(caTools) # for test / train split
library(e1071) # for SVM and Naive Bayes models

# read in data
data <- read.csv(
  "https://raw.githubusercontent.com/drehow/CSC-201/master/2020_Fall/20201102_Random_Forest/processed.cleveland.data",
  header=FALSE
)

dim(data)

# set header names
names(data) <- c("age", "sex", "cp", "trestbps", "choi", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thai", "num")

# convert y variable to binary
data$num[data$num > 1] <- 1

# convert classes
sapply(data, class)

data <- transform(
  data,
  age=as.integer(age),
  sex=as.factor(sex),
  cp=as.factor(cp),
  trestbps=as.integer(trestbps),
  choi=as.integer(choi),
  fbs=as.factor(fbs),
  restecg=as.factor(restecg),
  thalach=as.integer(thalach),
  exang=as.factor(exang),
  oldpeak=as.numeric(oldpeak),
  slope=as.factor(slope),
  ca=as.factor(ca),
  thai=as.factor(thai),
  num=as.factor(num)
)
sapply(data, class)

# handle NAs
data[ data == "?"] <- NA
colSums(is.na(data))

data$thai[which(is.na(data$thai))] <- as.factor("3.0")
data <- data[!(data$ca %in% c(NA)),]
colSums(is.na(data))
summary(data)

data$ca <- factor(data$ca)
data$thai <- factor(data$thai)
summary(data)

# train / test split
sample = sample.split(data$num, SplitRatio = .75)
train = subset(data, sample == TRUE)
test  = subset(data, sample == FALSE)
dim(train)
dim(test)

# random forest model
rf <- randomForest(
  num ~ .,
  data=train
  ,mtry = 6
  ,ntree = 500
)

# make predictions
pred = predict(rf, newdata=test[-14])

# make confusion matrix
cm <- table(test[,14], pred)
accuracy = 100 *(cm[1,1] + cm[2,2]) / (cm[1,2] + cm[2,1] + cm[1,1] + cm[2,2])

```

## Extra Credit
What would be one of the first things you would need to do to this data to train a neural net?

## Deliverables
For this lab, you only need to submit your R file in the dropbox on D2L. 
