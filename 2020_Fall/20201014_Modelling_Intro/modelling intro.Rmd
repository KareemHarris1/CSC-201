---
title: "Intro to Statistical Modelling"
author: "D. Howell"
date: "10/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

There's a lot of buzzy terminology around statistical modelling: machine learning, artificial intelligence, deep learning, regression, algorithms, classification, to name several. They are all based on the same concept: that you can make math-based predictions based on information about what has happened the past. What makes modelling so interesting is that it mirrors, more or less, what the human brain does hundreds of times a day in the process of making a decision. 

Let's say you have a friend who you regularly send tik tok videos to. You've sent them videos from 100 different accounts, and they always let you know how funny they find the video, either with a cool "lol" (video is not that funny), "Hahahaha" (video is pretty funny), or "HAHAHAHAHAAA OH MY GOD" (video is hilarious and they might have actually laughed out loud). Over time, you notice that your friend finds videos from certain accounts funnier than videos from other accounts that you send them in general. So if your goal is to make your friend laugh the most, you begin to filter your decision to send them a certain video through a model in your brain that gives you a certain level of confidence that your friend will think it is hilarious. You check first (consciously or subconsciously) what account posted the video to see if you remember if your friend likes videos from that account or not. If I see a video that replaces Joe Biden's body with Yoda's, I'd probably end up sending it to Chris and Daniel. If I see a video with funny commentary on that huge fly that landed on Pence's head in the VP debate, I'd send it to John. This is a statistical model because I'm deciding whether or not to send the video based on the political opinions these guys have offered up in past classes. 

So, with statistical models, that's always the premise: "I am x confident that y will happen, based on observations a, b, and c." In the remainder of the class, we will survey the different types of statistical models with this simple premise in mind. 

Now let's lay out the landscape for modelling. 

Statistical models are just equations of varying complexity. You could have something as simple as a linear model $y=mx+b$, or something more complex, like a Naive Vayes model $P(A|B) = \frac{P(A)*P(B|A)}{P(B)}$, on up to a convolutional neural network, which develops it's own equations! 

Given your knowledge of math already, you know that equations can be plotted. Let's use a linear model as an example. Say you have about a random sample of instagram users: how many followers they have and how many likes they usually get on a post. 

```{r}
followers <- 1:10000
likes <- 0.25*followers + 0

df <- data.frame(followers, likes)

library(ggplot2)
ggplot(df) + 
  geom_line(aes(x=followers,y=likes), color = 'red') + 
  theme_bw()

```

This red line represents a linear model. If you apply this model to a measurement x, it will tell you what it predicts y to be. So you have 500 followers and you make a bet with your friend that you will dive into a dumpster if your next post doesn't get a certain number of likes. The model says you're likely to get around 125 likes with a 10% confidence interval. You should try to negotiate the threshold to less than ~113 likes, or else you'll probably be smelling pretty bad in a few hours. 

The main defining difference between different types of models is the way they *fit* historical data mathematically. So the type of model tells you what shape the modelling equation is, a.k.a. what shape the line is, and then you fit that line shape to your data as close as you can. Let's fit a linear model to the iris data set. 

```{r}

df <- iris
ggplot(df) +
  geom_point(aes(x=df$Sepal.Width, y=Sepal.Length))

library(dplyr)
df <- select(df, Sepal.Width, Sepal.Length)

lm(Sepal.Length ~ Sepal.Width, df)

df$model <- 6.5262 + df$Sepal.Width*(-0.2234)

ggplot(df) +
  geom_point(aes(x=df$Sepal.Width, y=Sepal.Length)) + 
  geom_line(aes(x=df$Sepal.Width, y=df$model), color = 'red')

```

## Training Models

## Supervised vs Unsupervised

## Regression vs. Classification

## Model Evaluation

